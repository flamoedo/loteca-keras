{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = np.load('arquivo.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o ganhador H = casa, A = Vizitante, D = empate\n",
    "# for i in range(len(df)):\n",
    "#     df[i,8] = 'H' if (int(df[i,2]) - int(df[i,6])) > 0 else 'A' if (int(df[i,2]) - int(df[i,6])) < 0 else 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um data frame para receber os valores\n",
    "# df_ = pd.DataFrame(df,columns=['Concurso','Jogo','HG','Home','S','Away','AG','Dia','Res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma as colunas de gols em inteiros\n",
    "# df_ = df_.astype({\"HG\": int, \"AG\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencia de vitórias em casa (H), empates (D) e visitantes (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(df_['Res'].value_counts().keys(),df_['Res'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Média de gols dos últimos jogos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a soma de gols feitos das ultimas n (window) partidas\n",
    "# def get_rolling_goals(dataFrame, equip, pos, window, HG_AG):   \n",
    "#     HA = 'Home' if HG_AG == 'HG' else 'Away' if HG_AG == 'AG' else ''\n",
    "#     s = dataFrame[:pos][dataFrame[HA] == equip][HG_AG][-window:].sum()\n",
    "#     return s if not(np.isnan(s)) else 0\n",
    "\n",
    "# Calcula a soma de gols recebidos das ultimas n (window) partidas\n",
    "# def get_rolling_received(dataFrame, equip, pos, window, HG_AG):   \n",
    "#     HA = 'Home' if HG_AG == 'HG' else 'Away' if HG_AG == 'AG' else ''\n",
    "#     HG_AG_ = 'HG' if HG_AG == 'AG' else 'AG' if HG_AG == 'HG' else ''\n",
    "#     s = dataFrame[:pos][dataFrame[HA] == equip][HG_AG_][-window:].sum()\n",
    "#     return s if not(np.isnan(s)) else 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfg = []\n",
    "# for idx, row in df_.iterrows():\n",
    "#     row['H_Goals_Scored'] = get_rolling_goals(df_, row['Home'], idx, 20, 'HG')\n",
    "#     row['A_Goals_Scored'] = get_rolling_goals(df_, row['Away'], idx, 20, 'AG')\n",
    "#     row['H_Goals_Against'] = get_rolling_received(df_, row['Home'], idx, 20, 'HG')\n",
    "#     row['A_Goals_Against'] = get_rolling_received(df_, row['Away'], idx, 20, 'AG')\n",
    "#     dfg.append(row)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfgs = pd.DataFrame(dfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfgs[dfgs['Concurso']=='Concurso 800 (21/05/2018)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfgs.to_csv('arquivo_loteca1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv('arquivo_loteca1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Concurso</th>\n",
       "      <th>Jogo</th>\n",
       "      <th>HG</th>\n",
       "      <th>Home</th>\n",
       "      <th>S</th>\n",
       "      <th>Away</th>\n",
       "      <th>AG</th>\n",
       "      <th>Dia</th>\n",
       "      <th>Res</th>\n",
       "      <th>H_Goals_Scored</th>\n",
       "      <th>A_Goals_Scored</th>\n",
       "      <th>H_Goals_Against</th>\n",
       "      <th>A_Goals_Against</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>FLAMENGO/RJ</td>\n",
       "      <td></td>\n",
       "      <td>S. PAULO/SP</td>\n",
       "      <td>4</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>VASCO/RJ</td>\n",
       "      <td></td>\n",
       "      <td>AMERICANO/RJ</td>\n",
       "      <td>0</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>SANTOS/SP</td>\n",
       "      <td></td>\n",
       "      <td>SÃO CAETANO/SP</td>\n",
       "      <td>1</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>P. DESPORTOS/SP</td>\n",
       "      <td></td>\n",
       "      <td>CORINTHIANS/SP</td>\n",
       "      <td>4</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>CRUZEIRO/MG</td>\n",
       "      <td></td>\n",
       "      <td>AMÉRICA/MG</td>\n",
       "      <td>0</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Concurso  Jogo  HG             Home  S  \\\n",
       "0           0  Concurso 1 (18/02/2002)     1   2      FLAMENGO/RJ      \n",
       "1           1  Concurso 1 (18/02/2002)     2   3         VASCO/RJ      \n",
       "2           2  Concurso 1 (18/02/2002)     3   2        SANTOS/SP      \n",
       "3           3  Concurso 1 (18/02/2002)     4   1  P. DESPORTOS/SP      \n",
       "4           4  Concurso 1 (18/02/2002)     5   7      CRUZEIRO/MG      \n",
       "\n",
       "             Away  AG       Dia Res  H_Goals_Scored  A_Goals_Scored  \\\n",
       "0     S. PAULO/SP   4  Domingo    A               0               0   \n",
       "1    AMERICANO/RJ   0  Domingo    H               0               0   \n",
       "2  SÃO CAETANO/SP   1  Domingo    H               0               0   \n",
       "3  CORINTHIANS/SP   4  Domingo    A               0               0   \n",
       "4      AMÉRICA/MG   0   Sábado    H               0               0   \n",
       "\n",
       "   H_Goals_Against  A_Goals_Against  \n",
       "0                0                0  \n",
       "1                0                0  \n",
       "2                0                0  \n",
       "3                0                0  \n",
       "4                0                0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomes dos times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista de nomes dos times\n",
    "vocab = np.unique(np.concatenate((np.array(df_['Home'].unique()), np.array(df_['Away'].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o indice de times\n",
    "word2idx = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna o indice de um time:\n",
    "def word2vector(word):\n",
    "    m = np.zeros(len(word2idx))\n",
    "    idx = word2idx.get(word)\n",
    "    if idx == '':\n",
    "        raise ValueError('Time não encontrado no indice: ' + word)\n",
    "\n",
    "    m[word2idx.get(word)] = 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os dois times em um vetor com o flag do time correspondente e a média de gols\n",
    "def prepare(H,A):\n",
    "    \n",
    "    vector = []\n",
    "    \n",
    "    for x in word2vector(H):\n",
    "        if math.isnan(x):\n",
    "            raise ValueError('Time não encontrado no indice: ' + H)\n",
    "\n",
    "        vector.append(x)\n",
    "        \n",
    "    for x in word2vector(A):\n",
    "        if math.isnan(x):\n",
    "            raise ValueError('Time não encontrado no indice: ' + A)\n",
    "            \n",
    "        vector.append(x)\n",
    "                \n",
    "\n",
    "#     Cálculo das médias de gols\n",
    "#     vector.append(get_rolling_goals(df_, H, pos, 10, 'HG'))\n",
    "#     vector.append(get_rolling_goals(df_, A, pos, 10, 'AG'))\n",
    "    \n",
    "#     vector.append(get_rolling_received(df_, H, pos, 10, 'HG'))\n",
    "#     vector.append(get_rolling_received(df_, A, pos, 10, 'AG'))\n",
    "\n",
    "    \n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexar os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for ind_, row in df_.iterrows():\n",
    "    \n",
    "    vec = [word2vector(row['Home']), word2vector(row['Away'])]\n",
    "    \n",
    "    vec = np.array(vec).reshape(np.array(vec).shape[1]*2)\n",
    "    \n",
    "#     vec = np.append(vec, row['H_Goals_Scored'])\n",
    "#     vec = np.append(vec, row['A_Goals_Scored'])\n",
    "    \n",
    "    \n",
    "    X.append(vec)        \n",
    "    \n",
    "    ry = [1,0,0] if int(row['HG']) > int(row['AG']) else \\\n",
    "    [0,1,0] if int(row['HG']) == int(row['AG']) else \\\n",
    "    [0,0,1] if int(row['HG']) < int(row['AG']) else [0,0,0]\n",
    "\n",
    "    y.append(ry)\n",
    "\n",
    "y = np.array(y).reshape(np.array(y).shape[0],3)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# Normalizar gols\n",
    "# X[:,-4:-3] = X[:,-4:-3]/X[:,-4:-3].max()\n",
    "# X[:,-3:-2] = X[:,-3:-2]/X[:,-3:-2].max()\n",
    "# X[:,-2:-1] = X[:,-2:-1]/X[:,-2:-1].max()\n",
    "# X[:,-1:] = X[:,-1:]/X[:,-1:].max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, TimeDistributed\n",
    "from keras.layers import Embedding, Activation\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(64, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(64))  # return a single vector of dimension 32model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separar os datasets de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = []\n",
    "frame_size = 50\n",
    "for i in range(X.shape[0]):\n",
    "    \n",
    "    x_=(X[i-frame_size:i])\n",
    "    \n",
    "    xin.append(x_)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "xin = np.array(xin[frame_size:])\n",
    "yin = y[frame_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11510, 50, 1828)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = xin[:-int(xin.shape[0]/split)], yin[:-int(yin.shape[0]/split)], xin[-int(xin.shape[0]/split):], yin[-int(yin.shape[0]/split):],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "11223/11223 [==============================] - 26s 2ms/step - loss: 0.6149 - acc: 0.6674\n",
      "Epoch 2/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.6106 - acc: 0.6707\n",
      "Epoch 3/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.6088 - acc: 0.6717\n",
      "Epoch 4/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.6048 - acc: 0.6791\n",
      "Epoch 5/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.6004 - acc: 0.6822\n",
      "Epoch 6/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5972 - acc: 0.6867\n",
      "Epoch 7/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5935 - acc: 0.6892\n",
      "Epoch 8/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5911 - acc: 0.6897\n",
      "Epoch 9/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5891 - acc: 0.6916\n",
      "Epoch 10/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5859 - acc: 0.6947\n",
      "Epoch 11/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5844 - acc: 0.6946\n",
      "Epoch 12/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5812 - acc: 0.6975\n",
      "Epoch 13/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5793 - acc: 0.6979\n",
      "Epoch 14/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5778 - acc: 0.7000\n",
      "Epoch 15/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5751 - acc: 0.7020\n",
      "Epoch 16/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5727 - acc: 0.7018\n",
      "Epoch 17/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5712 - acc: 0.7017\n",
      "Epoch 18/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5693 - acc: 0.7033\n",
      "Epoch 19/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5674 - acc: 0.7045\n",
      "Epoch 20/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5653 - acc: 0.7062\n",
      "Epoch 21/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5641 - acc: 0.7069\n",
      "Epoch 22/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5623 - acc: 0.7088\n",
      "Epoch 23/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5591 - acc: 0.7123\n",
      "Epoch 24/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5584 - acc: 0.7123\n",
      "Epoch 25/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5574 - acc: 0.7116\n",
      "Epoch 26/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5556 - acc: 0.7126\n",
      "Epoch 27/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5528 - acc: 0.7134\n",
      "Epoch 28/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5515 - acc: 0.7165\n",
      "Epoch 29/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5507 - acc: 0.7172\n",
      "Epoch 30/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5474 - acc: 0.7192\n",
      "Epoch 31/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5468 - acc: 0.7178\n",
      "Epoch 32/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5440 - acc: 0.7204\n",
      "Epoch 33/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5426 - acc: 0.7200\n",
      "Epoch 34/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5407 - acc: 0.7212\n",
      "Epoch 35/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5389 - acc: 0.7231\n",
      "Epoch 36/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5380 - acc: 0.7243\n",
      "Epoch 37/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5352 - acc: 0.7239\n",
      "Epoch 38/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5338 - acc: 0.7247\n",
      "Epoch 39/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5317 - acc: 0.7255\n",
      "Epoch 40/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5302 - acc: 0.7264\n",
      "Epoch 41/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5278 - acc: 0.7292\n",
      "Epoch 42/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.5261 - acc: 0.7292\n",
      "Epoch 43/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.5241 - acc: 0.7301\n",
      "Epoch 44/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5205 - acc: 0.7334\n",
      "Epoch 45/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5196 - acc: 0.7327\n",
      "Epoch 46/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5165 - acc: 0.7356\n",
      "Epoch 47/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5140 - acc: 0.7348\n",
      "Epoch 48/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5135 - acc: 0.7356\n",
      "Epoch 49/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5091 - acc: 0.7381\n",
      "Epoch 50/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5067 - acc: 0.7414\n",
      "Epoch 51/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5033 - acc: 0.7431\n",
      "Epoch 52/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.5014 - acc: 0.7429\n",
      "Epoch 53/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4996 - acc: 0.7434\n",
      "Epoch 54/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4973 - acc: 0.7459\n",
      "Epoch 55/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4932 - acc: 0.7487\n",
      "Epoch 56/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4905 - acc: 0.7501\n",
      "Epoch 57/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4870 - acc: 0.7516\n",
      "Epoch 58/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.4843 - acc: 0.7516\n",
      "Epoch 59/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.4810 - acc: 0.7541\n",
      "Epoch 60/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4777 - acc: 0.7549\n",
      "Epoch 61/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4757 - acc: 0.7559\n",
      "Epoch 62/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4725 - acc: 0.7605\n",
      "Epoch 63/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4682 - acc: 0.7628\n",
      "Epoch 64/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4664 - acc: 0.7633\n",
      "Epoch 65/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4623 - acc: 0.7638\n",
      "Epoch 66/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4613 - acc: 0.7663\n",
      "Epoch 67/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4582 - acc: 0.7680\n",
      "Epoch 68/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4541 - acc: 0.7687\n",
      "Epoch 69/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4519 - acc: 0.7708\n",
      "Epoch 70/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4495 - acc: 0.7729\n",
      "Epoch 71/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4461 - acc: 0.7739\n",
      "Epoch 72/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4419 - acc: 0.7771\n",
      "Epoch 73/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4398 - acc: 0.7784\n",
      "Epoch 74/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4389 - acc: 0.7772\n",
      "Epoch 75/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.4361 - acc: 0.7812\n",
      "Epoch 76/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4339 - acc: 0.7805\n",
      "Epoch 77/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4289 - acc: 0.7829\n",
      "Epoch 78/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4256 - acc: 0.7859\n",
      "Epoch 79/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4223 - acc: 0.7884\n",
      "Epoch 80/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4199 - acc: 0.7906\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4207 - acc: 0.7881\n",
      "Epoch 82/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4134 - acc: 0.7922\n",
      "Epoch 83/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4113 - acc: 0.7936\n",
      "Epoch 84/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4086 - acc: 0.7954\n",
      "Epoch 85/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4056 - acc: 0.7982\n",
      "Epoch 86/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4039 - acc: 0.7980\n",
      "Epoch 87/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.4022 - acc: 0.7986\n",
      "Epoch 88/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3983 - acc: 0.8008\n",
      "Epoch 89/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3985 - acc: 0.8017\n",
      "Epoch 90/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3933 - acc: 0.8041\n",
      "Epoch 91/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3919 - acc: 0.8054\n",
      "Epoch 92/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3874 - acc: 0.8074\n",
      "Epoch 93/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3849 - acc: 0.8097\n",
      "Epoch 94/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.3841 - acc: 0.8113\n",
      "Epoch 95/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.3775 - acc: 0.8145\n",
      "Epoch 96/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3788 - acc: 0.8132\n",
      "Epoch 97/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3715 - acc: 0.8164\n",
      "Epoch 98/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3725 - acc: 0.8161\n",
      "Epoch 99/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3684 - acc: 0.8192\n",
      "Epoch 100/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3662 - acc: 0.8197\n",
      "Epoch 101/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3672 - acc: 0.8199\n",
      "Epoch 102/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3601 - acc: 0.8228\n",
      "Epoch 103/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.3565 - acc: 0.8268\n",
      "Epoch 104/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.3557 - acc: 0.8245\n",
      "Epoch 105/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.3516 - acc: 0.8267\n",
      "Epoch 106/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.3487 - acc: 0.8299\n",
      "Epoch 107/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.3508 - acc: 0.8281\n",
      "Epoch 108/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.3432 - acc: 0.8333\n",
      "Epoch 109/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.3423 - acc: 0.8344\n",
      "Epoch 110/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.3378 - acc: 0.8360\n",
      "Epoch 111/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.3391 - acc: 0.8357\n",
      "Epoch 112/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3343 - acc: 0.8385\n",
      "Epoch 113/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3295 - acc: 0.8422\n",
      "Epoch 114/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.3331 - acc: 0.8404\n",
      "Epoch 115/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3269 - acc: 0.8426\n",
      "Epoch 116/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.3230 - acc: 0.8451\n",
      "Epoch 117/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3205 - acc: 0.8479\n",
      "Epoch 118/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3200 - acc: 0.8471\n",
      "Epoch 119/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3160 - acc: 0.8490\n",
      "Epoch 120/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3168 - acc: 0.8483\n",
      "Epoch 121/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3123 - acc: 0.8505\n",
      "Epoch 122/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3119 - acc: 0.8521\n",
      "Epoch 123/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3041 - acc: 0.8548\n",
      "Epoch 124/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3056 - acc: 0.8550\n",
      "Epoch 125/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.3050 - acc: 0.8544\n",
      "Epoch 126/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2999 - acc: 0.8589\n",
      "Epoch 127/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2962 - acc: 0.8613\n",
      "Epoch 128/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2947 - acc: 0.8611\n",
      "Epoch 129/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2911 - acc: 0.8621\n",
      "Epoch 130/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2925 - acc: 0.8609\n",
      "Epoch 131/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2861 - acc: 0.8657\n",
      "Epoch 132/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2895 - acc: 0.8640\n",
      "Epoch 133/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2796 - acc: 0.8690\n",
      "Epoch 134/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2782 - acc: 0.8699\n",
      "Epoch 135/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2745 - acc: 0.8724\n",
      "Epoch 136/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2793 - acc: 0.8693\n",
      "Epoch 137/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2720 - acc: 0.8724\n",
      "Epoch 138/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.2742 - acc: 0.8719\n",
      "Epoch 139/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2655 - acc: 0.8768\n",
      "Epoch 140/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.2664 - acc: 0.8762\n",
      "Epoch 141/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.2631 - acc: 0.8790\n",
      "Epoch 142/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.2629 - acc: 0.8791\n",
      "Epoch 143/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.2525 - acc: 0.8850\n",
      "Epoch 144/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2585 - acc: 0.8814\n",
      "Epoch 145/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2541 - acc: 0.8840\n",
      "Epoch 146/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.2513 - acc: 0.8838\n",
      "Epoch 147/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2481 - acc: 0.8874\n",
      "Epoch 148/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.2472 - acc: 0.8855\n",
      "Epoch 149/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2468 - acc: 0.8875\n",
      "Epoch 150/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.2446 - acc: 0.8894\n",
      "Epoch 151/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2362 - acc: 0.8913\n",
      "Epoch 152/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2347 - acc: 0.8930\n",
      "Epoch 153/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2368 - acc: 0.8924\n",
      "Epoch 154/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2378 - acc: 0.8939\n",
      "Epoch 155/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2306 - acc: 0.8967\n",
      "Epoch 156/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2268 - acc: 0.8977\n",
      "Epoch 157/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2330 - acc: 0.8955\n",
      "Epoch 158/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.2265 - acc: 0.8978\n",
      "Epoch 159/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2181 - acc: 0.9018\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2266 - acc: 0.9001\n",
      "Epoch 161/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2152 - acc: 0.9053\n",
      "Epoch 162/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2181 - acc: 0.9024\n",
      "Epoch 163/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2081 - acc: 0.9082\n",
      "Epoch 164/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2124 - acc: 0.9071\n",
      "Epoch 165/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.2142 - acc: 0.9059\n",
      "Epoch 166/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2030 - acc: 0.9115\n",
      "Epoch 167/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.2096 - acc: 0.9080\n",
      "Epoch 168/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1965 - acc: 0.9142\n",
      "Epoch 169/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1989 - acc: 0.9126\n",
      "Epoch 170/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1968 - acc: 0.9146\n",
      "Epoch 171/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1946 - acc: 0.9164\n",
      "Epoch 172/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1919 - acc: 0.9167\n",
      "Epoch 173/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1893 - acc: 0.9181\n",
      "Epoch 174/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1911 - acc: 0.9179\n",
      "Epoch 175/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1885 - acc: 0.9175\n",
      "Epoch 176/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1830 - acc: 0.9196\n",
      "Epoch 177/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1850 - acc: 0.9215\n",
      "Epoch 178/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1781 - acc: 0.9241\n",
      "Epoch 179/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1818 - acc: 0.9227\n",
      "Epoch 180/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1781 - acc: 0.9246\n",
      "Epoch 181/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1714 - acc: 0.9275\n",
      "Epoch 182/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1752 - acc: 0.9270\n",
      "Epoch 183/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1644 - acc: 0.9307\n",
      "Epoch 184/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1724 - acc: 0.9275\n",
      "Epoch 185/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1600 - acc: 0.9325\n",
      "Epoch 186/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1681 - acc: 0.9290\n",
      "Epoch 187/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1572 - acc: 0.9342\n",
      "Epoch 188/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1707 - acc: 0.9274\n",
      "Epoch 189/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1525 - acc: 0.9372\n",
      "Epoch 190/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1574 - acc: 0.9348\n",
      "Epoch 191/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.1565 - acc: 0.9343\n",
      "Epoch 192/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1497 - acc: 0.9380\n",
      "Epoch 193/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1514 - acc: 0.9358\n",
      "Epoch 194/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1515 - acc: 0.9358\n",
      "Epoch 195/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1475 - acc: 0.9386\n",
      "Epoch 196/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1431 - acc: 0.9413\n",
      "Epoch 197/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1429 - acc: 0.9413\n",
      "Epoch 198/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1416 - acc: 0.9407\n",
      "Epoch 199/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1489 - acc: 0.9386\n",
      "Epoch 200/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1342 - acc: 0.9450\n",
      "Epoch 201/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1367 - acc: 0.9439\n",
      "Epoch 202/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1415 - acc: 0.9419\n",
      "Epoch 203/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1261 - acc: 0.9484\n",
      "Epoch 204/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1292 - acc: 0.9483\n",
      "Epoch 205/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1317 - acc: 0.9464\n",
      "Epoch 206/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1357 - acc: 0.9462\n",
      "Epoch 207/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1205 - acc: 0.9506\n",
      "Epoch 208/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1340 - acc: 0.9469\n",
      "Epoch 209/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1184 - acc: 0.9530\n",
      "Epoch 210/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1227 - acc: 0.9494\n",
      "Epoch 211/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1196 - acc: 0.9519\n",
      "Epoch 212/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1256 - acc: 0.9500\n",
      "Epoch 213/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1138 - acc: 0.9545\n",
      "Epoch 214/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1112 - acc: 0.9558\n",
      "Epoch 215/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1106 - acc: 0.9573\n",
      "Epoch 216/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1215 - acc: 0.9504\n",
      "Epoch 217/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1177 - acc: 0.9535\n",
      "Epoch 218/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1006 - acc: 0.9618\n",
      "Epoch 219/300\n",
      "11223/11223 [==============================] - 18s 2ms/step - loss: 0.1156 - acc: 0.9552\n",
      "Epoch 220/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1105 - acc: 0.9574\n",
      "Epoch 221/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1010 - acc: 0.9612\n",
      "Epoch 222/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.1055 - acc: 0.9586\n",
      "Epoch 223/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.1076 - acc: 0.9582\n",
      "Epoch 224/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0992 - acc: 0.9629\n",
      "Epoch 225/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.1034 - acc: 0.9600\n",
      "Epoch 226/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0935 - acc: 0.9631\n",
      "Epoch 227/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.1077 - acc: 0.9585\n",
      "Epoch 228/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.0945 - acc: 0.9639\n",
      "Epoch 229/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.1009 - acc: 0.9621\n",
      "Epoch 230/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0882 - acc: 0.9673\n",
      "Epoch 231/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.0973 - acc: 0.9637\n",
      "Epoch 232/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0817 - acc: 0.9702\n",
      "Epoch 233/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0965 - acc: 0.9633\n",
      "Epoch 234/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0874 - acc: 0.9688\n",
      "Epoch 235/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0926 - acc: 0.9647\n",
      "Epoch 236/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0878 - acc: 0.9682\n",
      "Epoch 237/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0867 - acc: 0.9672\n",
      "Epoch 238/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0903 - acc: 0.9660\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11223/11223 [==============================] - 18s 2ms/step - loss: 0.0722 - acc: 0.9730\n",
      "Epoch 240/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0912 - acc: 0.9663\n",
      "Epoch 241/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0776 - acc: 0.9712\n",
      "Epoch 242/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0832 - acc: 0.9687\n",
      "Epoch 243/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0784 - acc: 0.9711\n",
      "Epoch 244/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0718 - acc: 0.9739\n",
      "Epoch 245/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0775 - acc: 0.9726\n",
      "Epoch 246/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0794 - acc: 0.9718\n",
      "Epoch 247/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0706 - acc: 0.9755\n",
      "Epoch 248/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.0750 - acc: 0.9739\n",
      "Epoch 249/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0717 - acc: 0.9745\n",
      "Epoch 250/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0625 - acc: 0.9781\n",
      "Epoch 251/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0757 - acc: 0.9733\n",
      "Epoch 252/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0673 - acc: 0.9766\n",
      "Epoch 253/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0690 - acc: 0.9760\n",
      "Epoch 254/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0659 - acc: 0.9761\n",
      "Epoch 255/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0660 - acc: 0.9766\n",
      "Epoch 256/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0649 - acc: 0.9762\n",
      "Epoch 257/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0723 - acc: 0.9751\n",
      "Epoch 258/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0669 - acc: 0.9765\n",
      "Epoch 259/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0618 - acc: 0.9800\n",
      "Epoch 260/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0605 - acc: 0.9785\n",
      "Epoch 261/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0717 - acc: 0.9762\n",
      "Epoch 262/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0582 - acc: 0.9813\n",
      "Epoch 263/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0557 - acc: 0.9815\n",
      "Epoch 264/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0540 - acc: 0.9826\n",
      "Epoch 265/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.0743 - acc: 0.9739\n",
      "Epoch 266/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0479 - acc: 0.9830\n",
      "Epoch 267/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0565 - acc: 0.9816\n",
      "Epoch 268/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0561 - acc: 0.9804\n",
      "Epoch 269/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0563 - acc: 0.9814\n",
      "Epoch 270/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0587 - acc: 0.9797\n",
      "Epoch 271/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0493 - acc: 0.9848\n",
      "Epoch 272/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0481 - acc: 0.9846\n",
      "Epoch 273/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0556 - acc: 0.9813\n",
      "Epoch 274/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0565 - acc: 0.9806\n",
      "Epoch 275/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0451 - acc: 0.9859\n",
      "Epoch 276/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.0518 - acc: 0.9836\n",
      "Epoch 277/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0549 - acc: 0.9826\n",
      "Epoch 278/300\n",
      "11223/11223 [==============================] - 17s 1ms/step - loss: 0.0421 - acc: 0.9869\n",
      "Epoch 279/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0508 - acc: 0.9830\n",
      "Epoch 280/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0494 - acc: 0.9830\n",
      "Epoch 281/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0609 - acc: 0.9794\n",
      "Epoch 282/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0359 - acc: 0.9891\n",
      "Epoch 283/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0518 - acc: 0.9830\n",
      "Epoch 284/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0447 - acc: 0.9852\n",
      "Epoch 285/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0408 - acc: 0.9872\n",
      "Epoch 286/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0498 - acc: 0.9837\n",
      "Epoch 287/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0449 - acc: 0.9872\n",
      "Epoch 288/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0444 - acc: 0.9862\n",
      "Epoch 289/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0500 - acc: 0.9839\n",
      "Epoch 290/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0380 - acc: 0.9885\n",
      "Epoch 291/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0415 - acc: 0.9862\n",
      "Epoch 292/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0460 - acc: 0.9860\n",
      "Epoch 293/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0467 - acc: 0.9859\n",
      "Epoch 294/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0397 - acc: 0.9875\n",
      "Epoch 295/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0368 - acc: 0.9876\n",
      "Epoch 296/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0391 - acc: 0.9879\n",
      "Epoch 297/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0389 - acc: 0.9879\n",
      "Epoch 298/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0339 - acc: 0.9892\n",
      "Epoch 299/300\n",
      "11223/11223 [==============================] - 16s 1ms/step - loss: 0.0407 - acc: 0.9886\n",
      "Epoch 300/300\n",
      "11223/11223 [==============================] - 17s 2ms/step - loss: 0.0420 - acc: 0.9856\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=300, batch_size=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19eb6ba4cf8>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.882275353740732, 0.5865273043669059]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, \n",
    "               y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliar precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria as colunas com os resultados reais e as apostas\n",
    "def aposta(dr,p):\n",
    "    dr['RC1'] = 'X' if dr['HG'] > dr['AG'] else ''\n",
    "    dr['RCM'] = 'X' if dr['HG'] == dr['AG'] else ''\n",
    "    dr['RC2'] = 'X' if dr['HG'] < dr['AG'] else ''\n",
    "    \n",
    "    \n",
    "#     Criar apostas com jogos simples, duplos e triplos:\n",
    "    c=0\n",
    "    if p[0,0] > p.mean():\n",
    "        dr['AC1'] = 'X' \n",
    "        c += 1\n",
    "    else:\n",
    "        dr['AC1'] = ''\n",
    "    \n",
    "\n",
    "    if p[0,1] > p.mean():\n",
    "        dr['ACM'] = 'X' \n",
    "        c += 1\n",
    "    else:\n",
    "        dr['ACM'] = ''\n",
    "\n",
    "    if p[0,2] > p.mean():\n",
    "        dr['AC2'] = 'X' \n",
    "        c += 1\n",
    "    else:\n",
    "        dr['AC2'] = ''\n",
    "        \n",
    "#         Criar marcador de jogos duplos e triplos\n",
    "    if c==2:\n",
    "        dr['D']='D'\n",
    "    else:\n",
    "        dr['D']=''\n",
    "    if c==3:\n",
    "        dr['T']='T'\n",
    "    else:\n",
    "        dr['T']=''\n",
    "        \n",
    "\n",
    "    return dr\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.98 %\n"
     ]
    }
   ],
   "source": [
    "dfx = df_[int(-df_.shape[0]/split):]\n",
    "\n",
    "ds = []\n",
    "\n",
    "X_ = X[-int(X.shape[0]/split):]\n",
    "\n",
    "prec = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "y_true = []\n",
    "\n",
    "y_prec = []\n",
    "\n",
    "for row in X_test:    \n",
    "\n",
    "    p = model.predict([[row]])\n",
    "    \n",
    "    m = p[0].max()\n",
    "    \n",
    "    r = [1,0,0] if p[0,0] == m else [0,1,0] if p[0,1] == m else [0,0,1] if p[0,2] == m else [0,0,0]       \n",
    "    \n",
    "    a = 1 if (r == y_test[i]).all() else 0\n",
    "    \n",
    "    prec.append(r)   \n",
    "    \n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#     Cria um dataframe com os resultados para report\n",
    "    ds.append(a)    \n",
    "    \n",
    "print(round(((np.mean(ds))) * 100,2), '%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289, 3)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = ConfusionMatrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-b400850492e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas_ml\\confusion_matrix\\cm.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, y_true, y_pred, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniq_true\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniq_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbcm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBinaryConfusionMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mBinaryConfusionMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mLabeledConfusionMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# super(BinaryConfusionMatrix, self).__init__(y_true, y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBinaryConfusionMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0;31m\"\u001b[0m\u001b[0mBinary\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[0mbut\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas_ml\\confusion_matrix\\abstract.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y_true, y_pred, labels, display_sum, backend, true_name, pred_name)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[1;32m--> 275\u001b[1;33m                                        raise_cast_failure=True)\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m   4163\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4165\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4166\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4167\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_asarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "confusion_matrix = ConfusionMatrix(y_test, prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs['Concurso']=='Concurso 825 (05/11/2018)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs['S']==dfs['Res']].groupby(['Concurso'])['Concurso'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considera os duplos e triplos\n",
    "# RC1\tRCM\tRC2\tAC1\tACM\tAC2\n",
    "dfs[((dfs['RC1']==dfs['AC1'])&(dfs['RC1']=='X')) | ((dfs['RC2']==dfs['AC2'])&(dfs['RC2']=='X')) | ((dfs['RCM']==dfs['ACM'])&(dfs['RCM']=='X'))].groupby(['Concurso'])['Concurso'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preço das apostas\n",
    "2**dfs[dfs['D']=='D'].groupby(['Concurso'])['Concurso'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 'LIVERPOOL/ING'\n",
    "A = 'TOTTENHAM/ING'\n",
    "\n",
    "prep = [prepare(H,A,1)]\n",
    "    \n",
    "prepx = np.array(prep).reshape(np.array(prep).shape[0],np.array(prep).shape[1])\n",
    "    \n",
    "p = model.predict(prepx)\n",
    "\n",
    "\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
