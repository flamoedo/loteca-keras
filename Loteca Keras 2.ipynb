{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.load('arquivo.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[i,8] = 'H' if (int(df[i,2]) - int(df[i,6])) > 0 else 'A' if (int(df[i,2]) - int(df[i,6])) < 0 else 'D'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame(df,columns=['Concurso','Jogo','HG','Home','S','Away','AG','Dia','Res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concurso</th>\n",
       "      <th>Jogo</th>\n",
       "      <th>HG</th>\n",
       "      <th>Home</th>\n",
       "      <th>S</th>\n",
       "      <th>Away</th>\n",
       "      <th>AG</th>\n",
       "      <th>Dia</th>\n",
       "      <th>Res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>FLAMENGO/RJ</td>\n",
       "      <td></td>\n",
       "      <td>S. PAULO/SP</td>\n",
       "      <td>4</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>VASCO/RJ</td>\n",
       "      <td></td>\n",
       "      <td>AMERICANO/RJ</td>\n",
       "      <td>0</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>SANTOS/SP</td>\n",
       "      <td></td>\n",
       "      <td>SÃO CAETANO/SP</td>\n",
       "      <td>1</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>P. DESPORTOS/SP</td>\n",
       "      <td></td>\n",
       "      <td>CORINTHIANS/SP</td>\n",
       "      <td>4</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Concurso 1 (18/02/2002)</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>CRUZEIRO/MG</td>\n",
       "      <td></td>\n",
       "      <td>AMÉRICA/MG</td>\n",
       "      <td>0</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Concurso Jogo HG             Home  S            Away AG  \\\n",
       "0  Concurso 1 (18/02/2002)    1  2      FLAMENGO/RJ        S. PAULO/SP  4   \n",
       "1  Concurso 1 (18/02/2002)    2  3         VASCO/RJ       AMERICANO/RJ  0   \n",
       "2  Concurso 1 (18/02/2002)    3  2        SANTOS/SP     SÃO CAETANO/SP  1   \n",
       "3  Concurso 1 (18/02/2002)    4  1  P. DESPORTOS/SP     CORINTHIANS/SP  4   \n",
       "4  Concurso 1 (18/02/2002)    5  7      CRUZEIRO/MG         AMÉRICA/MG  0   \n",
       "\n",
       "        Dia Res  \n",
       "0  Domingo    A  \n",
       "1  Domingo    H  \n",
       "2  Domingo    H  \n",
       "3  Domingo    A  \n",
       "4   Sábado    H  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencia de vitórias em casa (H), empates (D) e visitantes (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(df_['Res'].value_counts().keys(),df_['Res'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomes dos times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.unique(np.concatenate((np.array(df_['Home'].unique()), np.array(df_['Away'].unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformar em índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vector(word):\n",
    "    m = np.zeros(len(word2idx))\n",
    "    m[word2idx.get(word)] = 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os dois times em um vetor com o flag do time correspondente\n",
    "def prepare(H,A):\n",
    "    \n",
    "#     return([word2idx.get(H),word2idx.get(A)])\n",
    "    \n",
    "    return [word2vector(H), word2vector(A)]\n",
    "#     return np.array(vec).reshape(np.array(vec).shape[1],2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para indexar os jogos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text_to_vector2(text): \n",
    "#     return word2idx.get(text, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexar os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for _, row in df_.iterrows():\n",
    "    X.append(prepare(row['Home'], row['Away']))    \n",
    "    \n",
    "    n = -int(row['HG']) + int(row['AG'])\n",
    "    \n",
    "    if np.isnan(n):\n",
    "        n = 0\n",
    "    \n",
    "    y.append([1,0,0] if n < 0 else [0,0,1] if n > 0 else [0,1,0])\n",
    "\n",
    "y = np.array(y).reshape(np.array(y).shape[0],3)\n",
    "\n",
    "X = np.array(X).reshape(np.array(X).shape[0],np.array(X).shape[2]*2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(124, input_shape=(np.array(X).shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(62, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(62, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separar os datasets de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "7745/7745 [==============================] - 1s 91us/step - loss: 0.3793 - acc: 0.8121\n",
      "Epoch 2/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3818 - acc: 0.8096\n",
      "Epoch 3/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3812 - acc: 0.8112\n",
      "Epoch 4/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3785 - acc: 0.8118\n",
      "Epoch 5/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3835 - acc: 0.8081\n",
      "Epoch 6/2000\n",
      "7745/7745 [==============================] - 1s 84us/step - loss: 0.3838 - acc: 0.8086\n",
      "Epoch 7/2000\n",
      "7745/7745 [==============================] - 1s 84us/step - loss: 0.3746 - acc: 0.8134\n",
      "Epoch 8/2000\n",
      "7745/7745 [==============================] - 1s 94us/step - loss: 0.3818 - acc: 0.8113\n",
      "Epoch 9/2000\n",
      "7745/7745 [==============================] - 1s 84us/step - loss: 0.3823 - acc: 0.8108\n",
      "Epoch 10/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3794 - acc: 0.8087\n",
      "Epoch 11/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3792 - acc: 0.8107\n",
      "Epoch 12/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3817 - acc: 0.8071\n",
      "Epoch 13/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3811 - acc: 0.8093\n",
      "Epoch 14/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3847 - acc: 0.8071\n",
      "Epoch 15/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3807 - acc: 0.8088\n",
      "Epoch 16/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3778 - acc: 0.8109\n",
      "Epoch 17/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3752 - acc: 0.8099\n",
      "Epoch 18/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3761 - acc: 0.8110\n",
      "Epoch 19/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3768 - acc: 0.8092\n",
      "Epoch 20/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3814 - acc: 0.8115\n",
      "Epoch 21/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3791 - acc: 0.8078\n",
      "Epoch 22/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3808 - acc: 0.8073\n",
      "Epoch 23/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3829 - acc: 0.8084\n",
      "Epoch 24/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3778 - acc: 0.8099\n",
      "Epoch 25/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3783 - acc: 0.8102\n",
      "Epoch 26/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3777 - acc: 0.8115\n",
      "Epoch 27/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3813 - acc: 0.8088\n",
      "Epoch 28/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3796 - acc: 0.8085\n",
      "Epoch 29/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3767 - acc: 0.8112\n",
      "Epoch 30/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3791 - acc: 0.8093\n",
      "Epoch 31/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3795 - acc: 0.8102\n",
      "Epoch 32/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3790 - acc: 0.8086\n",
      "Epoch 33/2000\n",
      "7745/7745 [==============================] - 1s 84us/step - loss: 0.3779 - acc: 0.8091\n",
      "Epoch 34/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3778 - acc: 0.8078\n",
      "Epoch 35/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3746 - acc: 0.8096\n",
      "Epoch 36/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3804 - acc: 0.8088\n",
      "Epoch 37/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3782 - acc: 0.8111\n",
      "Epoch 38/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3805 - acc: 0.8096\n",
      "Epoch 39/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3781 - acc: 0.8126\n",
      "Epoch 40/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3782 - acc: 0.8090\n",
      "Epoch 41/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3789 - acc: 0.8114\n",
      "Epoch 42/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3759 - acc: 0.8120\n",
      "Epoch 43/2000\n",
      "7745/7745 [==============================] - 1s 83us/step - loss: 0.3811 - acc: 0.8104\n",
      "Epoch 44/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3819 - acc: 0.8086\n",
      "Epoch 45/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3750 - acc: 0.8118\n",
      "Epoch 46/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3775 - acc: 0.8103\n",
      "Epoch 47/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3759 - acc: 0.8093\n",
      "Epoch 48/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3759 - acc: 0.8125\n",
      "Epoch 49/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3803 - acc: 0.8110\n",
      "Epoch 50/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3747 - acc: 0.8094\n",
      "Epoch 51/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3766 - acc: 0.8113\n",
      "Epoch 52/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3807 - acc: 0.8108\n",
      "Epoch 53/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3768 - acc: 0.8115\n",
      "Epoch 54/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3773 - acc: 0.8114\n",
      "Epoch 55/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3796 - acc: 0.8121\n",
      "Epoch 56/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3795 - acc: 0.8091\n",
      "Epoch 57/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3743 - acc: 0.8139\n",
      "Epoch 58/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3759 - acc: 0.8106\n",
      "Epoch 59/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3766 - acc: 0.8106\n",
      "Epoch 60/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3760 - acc: 0.8081\n",
      "Epoch 61/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3793 - acc: 0.8110\n",
      "Epoch 62/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3746 - acc: 0.8125\n",
      "Epoch 63/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3799 - acc: 0.8087\n",
      "Epoch 64/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3773 - acc: 0.8091\n",
      "Epoch 65/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3792 - acc: 0.8085\n",
      "Epoch 66/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3745 - acc: 0.8125\n",
      "Epoch 67/2000\n",
      "7745/7745 [==============================] - 1s 86us/step - loss: 0.3777 - acc: 0.8087\n",
      "Epoch 68/2000\n",
      "7745/7745 [==============================] - 1s 86us/step - loss: 0.3767 - acc: 0.8099\n",
      "Epoch 69/2000\n",
      "7745/7745 [==============================] - 1s 83us/step - loss: 0.3779 - acc: 0.8098\n",
      "Epoch 70/2000\n",
      "7745/7745 [==============================] - 1s 84us/step - loss: 0.3743 - acc: 0.8109\n",
      "Epoch 71/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3773 - acc: 0.8111\n",
      "Epoch 72/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3754 - acc: 0.8116\n",
      "Epoch 73/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3744 - acc: 0.8120\n",
      "Epoch 74/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3793 - acc: 0.8075\n",
      "Epoch 75/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3760 - acc: 0.8106\n",
      "Epoch 76/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3759 - acc: 0.8109\n",
      "Epoch 77/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3738 - acc: 0.8112\n",
      "Epoch 78/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3769 - acc: 0.8120\n",
      "Epoch 79/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3738 - acc: 0.8121\n",
      "Epoch 80/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3775 - acc: 0.8094\n",
      "Epoch 81/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3749 - acc: 0.8111\n",
      "Epoch 82/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3763 - acc: 0.8093\n",
      "Epoch 83/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3757 - acc: 0.8088\n",
      "Epoch 84/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3750 - acc: 0.8109\n",
      "Epoch 85/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3748 - acc: 0.8114\n",
      "Epoch 86/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3730 - acc: 0.8127\n",
      "Epoch 87/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3722 - acc: 0.8113\n",
      "Epoch 88/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3782 - acc: 0.8071\n",
      "Epoch 89/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3735 - acc: 0.8108\n",
      "Epoch 90/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3742 - acc: 0.8122\n",
      "Epoch 91/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3739 - acc: 0.8092\n",
      "Epoch 92/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3730 - acc: 0.8118\n",
      "Epoch 93/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3754 - acc: 0.8084\n",
      "Epoch 94/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3761 - acc: 0.8098\n",
      "Epoch 95/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3772 - acc: 0.8096\n",
      "Epoch 96/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3749 - acc: 0.8108\n",
      "Epoch 97/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3796 - acc: 0.8108\n",
      "Epoch 98/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3740 - acc: 0.8122\n",
      "Epoch 99/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3726 - acc: 0.8127\n",
      "Epoch 100/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3753 - acc: 0.8093\n",
      "Epoch 101/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3765 - acc: 0.8109\n",
      "Epoch 102/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3739 - acc: 0.8108\n",
      "Epoch 103/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3748 - acc: 0.8105\n",
      "Epoch 104/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3779 - acc: 0.8078\n",
      "Epoch 105/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3716 - acc: 0.8127\n",
      "Epoch 106/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3720 - acc: 0.8126\n",
      "Epoch 107/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3729 - acc: 0.8109\n",
      "Epoch 108/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3732 - acc: 0.8094\n",
      "Epoch 109/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3772 - acc: 0.8099\n",
      "Epoch 110/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3754 - acc: 0.8105\n",
      "Epoch 111/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3730 - acc: 0.8115\n",
      "Epoch 112/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3704 - acc: 0.8130\n",
      "Epoch 113/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3767 - acc: 0.8104\n",
      "Epoch 114/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3768 - acc: 0.8099\n",
      "Epoch 115/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3729 - acc: 0.8122\n",
      "Epoch 116/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3708 - acc: 0.8119\n",
      "Epoch 117/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3712 - acc: 0.8132\n",
      "Epoch 118/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3688 - acc: 0.8119\n",
      "Epoch 119/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3726 - acc: 0.8123\n",
      "Epoch 120/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3782 - acc: 0.8094\n",
      "Epoch 121/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3755 - acc: 0.8119\n",
      "Epoch 122/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3731 - acc: 0.8124\n",
      "Epoch 123/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3729 - acc: 0.8111\n",
      "Epoch 124/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3737 - acc: 0.8124\n",
      "Epoch 125/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3695 - acc: 0.8110\n",
      "Epoch 126/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3709 - acc: 0.8133\n",
      "Epoch 127/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3727 - acc: 0.8121\n",
      "Epoch 128/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3712 - acc: 0.8114\n",
      "Epoch 129/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3721 - acc: 0.8103\n",
      "Epoch 130/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3731 - acc: 0.8122\n",
      "Epoch 131/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3730 - acc: 0.8094\n",
      "Epoch 132/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3748 - acc: 0.8114\n",
      "Epoch 133/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3702 - acc: 0.8145\n",
      "Epoch 134/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3721 - acc: 0.8133\n",
      "Epoch 135/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3741 - acc: 0.8092\n",
      "Epoch 136/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3722 - acc: 0.8115\n",
      "Epoch 137/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3743 - acc: 0.8067\n",
      "Epoch 138/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3728 - acc: 0.8097\n",
      "Epoch 139/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3729 - acc: 0.8119\n",
      "Epoch 140/2000\n",
      "7745/7745 [==============================] - 1s 83us/step - loss: 0.3705 - acc: 0.8134\n",
      "Epoch 141/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3753 - acc: 0.8114\n",
      "Epoch 142/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3713 - acc: 0.8122\n",
      "Epoch 143/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3722 - acc: 0.8105\n",
      "Epoch 144/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3734 - acc: 0.8115\n",
      "Epoch 145/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3715 - acc: 0.8105\n",
      "Epoch 146/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3686 - acc: 0.8148\n",
      "Epoch 147/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3752 - acc: 0.8091\n",
      "Epoch 148/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3734 - acc: 0.8119\n",
      "Epoch 149/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3726 - acc: 0.8135\n",
      "Epoch 150/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3716 - acc: 0.8096\n",
      "Epoch 151/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3700 - acc: 0.8125\n",
      "Epoch 152/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3699 - acc: 0.8120\n",
      "Epoch 153/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3739 - acc: 0.8100\n",
      "Epoch 154/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3706 - acc: 0.8112\n",
      "Epoch 155/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3718 - acc: 0.8115\n",
      "Epoch 156/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3744 - acc: 0.8098\n",
      "Epoch 157/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3709 - acc: 0.8127\n",
      "Epoch 158/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3754 - acc: 0.8100\n",
      "Epoch 159/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3741 - acc: 0.8102\n",
      "Epoch 160/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3719 - acc: 0.8144\n",
      "Epoch 161/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3748 - acc: 0.8090\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3747 - acc: 0.8080\n",
      "Epoch 163/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3710 - acc: 0.8122\n",
      "Epoch 164/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3681 - acc: 0.8119\n",
      "Epoch 165/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3720 - acc: 0.8108\n",
      "Epoch 166/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3761 - acc: 0.8089\n",
      "Epoch 167/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3742 - acc: 0.8115\n",
      "Epoch 168/2000\n",
      "7745/7745 [==============================] - 1s 97us/step - loss: 0.3725 - acc: 0.8127\n",
      "Epoch 169/2000\n",
      "7745/7745 [==============================] - 1s 91us/step - loss: 0.3704 - acc: 0.8123\n",
      "Epoch 170/2000\n",
      "7745/7745 [==============================] - 1s 88us/step - loss: 0.3727 - acc: 0.8119\n",
      "Epoch 171/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3693 - acc: 0.8130\n",
      "Epoch 172/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3711 - acc: 0.8121\n",
      "Epoch 173/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3710 - acc: 0.8104\n",
      "Epoch 174/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3711 - acc: 0.8107\n",
      "Epoch 175/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3735 - acc: 0.8112\n",
      "Epoch 176/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3736 - acc: 0.8090\n",
      "Epoch 177/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3686 - acc: 0.8124\n",
      "Epoch 178/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3712 - acc: 0.8110\n",
      "Epoch 179/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3748 - acc: 0.8086\n",
      "Epoch 180/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3701 - acc: 0.8113\n",
      "Epoch 181/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3745 - acc: 0.8118\n",
      "Epoch 182/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3745 - acc: 0.8111\n",
      "Epoch 183/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3695 - acc: 0.8136\n",
      "Epoch 184/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3716 - acc: 0.8093\n",
      "Epoch 185/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3716 - acc: 0.8131\n",
      "Epoch 186/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3755 - acc: 0.8097\n",
      "Epoch 187/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3692 - acc: 0.8125\n",
      "Epoch 188/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3731 - acc: 0.8083\n",
      "Epoch 189/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3697 - acc: 0.8111\n",
      "Epoch 190/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3661 - acc: 0.8131\n",
      "Epoch 191/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3717 - acc: 0.8103\n",
      "Epoch 192/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3702 - acc: 0.8130\n",
      "Epoch 193/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3712 - acc: 0.8117\n",
      "Epoch 194/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3680 - acc: 0.8110\n",
      "Epoch 195/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3727 - acc: 0.8090\n",
      "Epoch 196/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3699 - acc: 0.8106\n",
      "Epoch 197/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3706 - acc: 0.8124\n",
      "Epoch 198/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3685 - acc: 0.8127\n",
      "Epoch 199/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3695 - acc: 0.8098\n",
      "Epoch 200/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3701 - acc: 0.8113\n",
      "Epoch 201/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3715 - acc: 0.8091\n",
      "Epoch 202/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3718 - acc: 0.8111\n",
      "Epoch 203/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3685 - acc: 0.8105\n",
      "Epoch 204/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3710 - acc: 0.8117\n",
      "Epoch 205/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3701 - acc: 0.8116\n",
      "Epoch 206/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3678 - acc: 0.8139\n",
      "Epoch 207/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3672 - acc: 0.8130\n",
      "Epoch 208/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3670 - acc: 0.8133\n",
      "Epoch 209/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3672 - acc: 0.8129\n",
      "Epoch 210/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3697 - acc: 0.8117\n",
      "Epoch 211/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3728 - acc: 0.8088\n",
      "Epoch 212/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3716 - acc: 0.8130\n",
      "Epoch 213/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3660 - acc: 0.8128\n",
      "Epoch 214/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3683 - acc: 0.8118\n",
      "Epoch 215/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3709 - acc: 0.8095\n",
      "Epoch 216/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3714 - acc: 0.8105\n",
      "Epoch 217/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3709 - acc: 0.8100\n",
      "Epoch 218/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3700 - acc: 0.8083\n",
      "Epoch 219/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3687 - acc: 0.8136\n",
      "Epoch 220/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3710 - acc: 0.8091\n",
      "Epoch 221/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3686 - acc: 0.8110\n",
      "Epoch 222/2000\n",
      "7745/7745 [==============================] - 1s 84us/step - loss: 0.3674 - acc: 0.8133\n",
      "Epoch 223/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3700 - acc: 0.8129\n",
      "Epoch 224/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3722 - acc: 0.8122\n",
      "Epoch 225/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3669 - acc: 0.8122\n",
      "Epoch 226/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3713 - acc: 0.8115\n",
      "Epoch 227/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3678 - acc: 0.8116\n",
      "Epoch 228/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3698 - acc: 0.8096\n",
      "Epoch 229/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3686 - acc: 0.8115\n",
      "Epoch 230/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3644 - acc: 0.8116\n",
      "Epoch 231/2000\n",
      "7745/7745 [==============================] - 1s 83us/step - loss: 0.3716 - acc: 0.8120\n",
      "Epoch 232/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3706 - acc: 0.8124\n",
      "Epoch 233/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3682 - acc: 0.8125\n",
      "Epoch 234/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3670 - acc: 0.8129\n",
      "Epoch 235/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3696 - acc: 0.8128\n",
      "Epoch 236/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3684 - acc: 0.8116\n",
      "Epoch 237/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3705 - acc: 0.8121\n",
      "Epoch 238/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3685 - acc: 0.8122\n",
      "Epoch 239/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3698 - acc: 0.8138\n",
      "Epoch 240/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3693 - acc: 0.8109\n",
      "Epoch 241/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3663 - acc: 0.8087\n",
      "Epoch 242/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3705 - acc: 0.8093\n",
      "Epoch 243/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3665 - acc: 0.8131\n",
      "Epoch 244/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3714 - acc: 0.8093\n",
      "Epoch 245/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3661 - acc: 0.8129\n",
      "Epoch 246/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3693 - acc: 0.8127\n",
      "Epoch 247/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3689 - acc: 0.8130\n",
      "Epoch 248/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3676 - acc: 0.8110\n",
      "Epoch 249/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3734 - acc: 0.8098\n",
      "Epoch 250/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3696 - acc: 0.8124\n",
      "Epoch 251/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3664 - acc: 0.8144\n",
      "Epoch 252/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3689 - acc: 0.8123\n",
      "Epoch 253/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3709 - acc: 0.8105\n",
      "Epoch 254/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3679 - acc: 0.8130\n",
      "Epoch 255/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3684 - acc: 0.8102\n",
      "Epoch 256/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3676 - acc: 0.8115\n",
      "Epoch 257/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3682 - acc: 0.8123\n",
      "Epoch 258/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3675 - acc: 0.8087\n",
      "Epoch 259/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3657 - acc: 0.8138\n",
      "Epoch 260/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3681 - acc: 0.8117\n",
      "Epoch 261/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3709 - acc: 0.8122\n",
      "Epoch 262/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3669 - acc: 0.8125\n",
      "Epoch 263/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3686 - acc: 0.8110\n",
      "Epoch 264/2000\n",
      "7745/7745 [==============================] - 1s 85us/step - loss: 0.3654 - acc: 0.8115\n",
      "Epoch 265/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3661 - acc: 0.8100\n",
      "Epoch 266/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3662 - acc: 0.8131\n",
      "Epoch 267/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3683 - acc: 0.8114\n",
      "Epoch 268/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3675 - acc: 0.8102\n",
      "Epoch 269/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3689 - acc: 0.8120\n",
      "Epoch 270/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3653 - acc: 0.8133\n",
      "Epoch 271/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3657 - acc: 0.8134\n",
      "Epoch 272/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3647 - acc: 0.8152\n",
      "Epoch 273/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3670 - acc: 0.8116\n",
      "Epoch 274/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3661 - acc: 0.8136\n",
      "Epoch 275/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3628 - acc: 0.8147\n",
      "Epoch 276/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3662 - acc: 0.8117\n",
      "Epoch 277/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3708 - acc: 0.8072\n",
      "Epoch 278/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3702 - acc: 0.8108\n",
      "Epoch 279/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3669 - acc: 0.8118\n",
      "Epoch 280/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3670 - acc: 0.8113\n",
      "Epoch 281/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3690 - acc: 0.8105\n",
      "Epoch 282/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3712 - acc: 0.8100\n",
      "Epoch 283/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3667 - acc: 0.8108\n",
      "Epoch 284/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3644 - acc: 0.8131\n",
      "Epoch 285/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3684 - acc: 0.8118\n",
      "Epoch 286/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3688 - acc: 0.8115\n",
      "Epoch 287/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3630 - acc: 0.8140\n",
      "Epoch 288/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3668 - acc: 0.8110\n",
      "Epoch 289/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3640 - acc: 0.8150\n",
      "Epoch 290/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3667 - acc: 0.8121\n",
      "Epoch 291/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3707 - acc: 0.8102\n",
      "Epoch 292/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3670 - acc: 0.8119\n",
      "Epoch 293/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3635 - acc: 0.8134\n",
      "Epoch 294/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3679 - acc: 0.8114\n",
      "Epoch 295/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3650 - acc: 0.8124\n",
      "Epoch 296/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3659 - acc: 0.8133\n",
      "Epoch 297/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3661 - acc: 0.8136\n",
      "Epoch 298/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3663 - acc: 0.8136\n",
      "Epoch 299/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3710 - acc: 0.8105\n",
      "Epoch 300/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3660 - acc: 0.8120\n",
      "Epoch 301/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3666 - acc: 0.8134\n",
      "Epoch 302/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3671 - acc: 0.8117\n",
      "Epoch 303/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3663 - acc: 0.8100\n",
      "Epoch 304/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3696 - acc: 0.8137\n",
      "Epoch 305/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3665 - acc: 0.8120\n",
      "Epoch 306/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3691 - acc: 0.8118\n",
      "Epoch 307/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3652 - acc: 0.8126\n",
      "Epoch 308/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3661 - acc: 0.8117\n",
      "Epoch 309/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3653 - acc: 0.8133\n",
      "Epoch 310/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3643 - acc: 0.8139\n",
      "Epoch 311/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3677 - acc: 0.8127\n",
      "Epoch 312/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3647 - acc: 0.8151\n",
      "Epoch 313/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3653 - acc: 0.8130\n",
      "Epoch 314/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3619 - acc: 0.8153\n",
      "Epoch 315/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3644 - acc: 0.8124\n",
      "Epoch 316/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3679 - acc: 0.8108\n",
      "Epoch 317/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3660 - acc: 0.8132\n",
      "Epoch 318/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3664 - acc: 0.8127\n",
      "Epoch 319/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3674 - acc: 0.8095\n",
      "Epoch 320/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3657 - acc: 0.8110\n",
      "Epoch 321/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3637 - acc: 0.8150\n",
      "Epoch 322/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3645 - acc: 0.8100\n",
      "Epoch 323/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3618 - acc: 0.8133\n",
      "Epoch 324/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3654 - acc: 0.8124\n",
      "Epoch 325/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3640 - acc: 0.8130\n",
      "Epoch 326/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3664 - acc: 0.8099\n",
      "Epoch 327/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3649 - acc: 0.8126\n",
      "Epoch 328/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3652 - acc: 0.8108\n",
      "Epoch 329/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3635 - acc: 0.8126\n",
      "Epoch 330/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3654 - acc: 0.8118\n",
      "Epoch 331/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3648 - acc: 0.8099\n",
      "Epoch 332/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3654 - acc: 0.8125\n",
      "Epoch 333/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3631 - acc: 0.8122\n",
      "Epoch 334/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3619 - acc: 0.8117\n",
      "Epoch 335/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3603 - acc: 0.8151\n",
      "Epoch 336/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3662 - acc: 0.8121\n",
      "Epoch 337/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3705 - acc: 0.8087\n",
      "Epoch 338/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3627 - acc: 0.8140\n",
      "Epoch 339/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3601 - acc: 0.8138\n",
      "Epoch 340/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3651 - acc: 0.8135\n",
      "Epoch 341/2000\n",
      "7745/7745 [==============================] - 1s 83us/step - loss: 0.3664 - acc: 0.8101\n",
      "Epoch 342/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3659 - acc: 0.8111\n",
      "Epoch 343/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3652 - acc: 0.8133\n",
      "Epoch 344/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3649 - acc: 0.8104\n",
      "Epoch 345/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3661 - acc: 0.8115\n",
      "Epoch 346/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3663 - acc: 0.8117\n",
      "Epoch 347/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3654 - acc: 0.8132\n",
      "Epoch 348/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3624 - acc: 0.8135\n",
      "Epoch 349/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3657 - acc: 0.8114\n",
      "Epoch 350/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3630 - acc: 0.8144\n",
      "Epoch 351/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3651 - acc: 0.8104\n",
      "Epoch 352/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3666 - acc: 0.8111\n",
      "Epoch 353/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3658 - acc: 0.8112\n",
      "Epoch 354/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3671 - acc: 0.8105\n",
      "Epoch 355/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3655 - acc: 0.8131\n",
      "Epoch 356/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3639 - acc: 0.8135\n",
      "Epoch 357/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3667 - acc: 0.8115\n",
      "Epoch 358/2000\n",
      "7745/7745 [==============================] - 1s 87us/step - loss: 0.3644 - acc: 0.8114\n",
      "Epoch 359/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3646 - acc: 0.8136\n",
      "Epoch 360/2000\n",
      "7745/7745 [==============================] - 1s 92us/step - loss: 0.3650 - acc: 0.8118\n",
      "Epoch 361/2000\n",
      "7745/7745 [==============================] - 1s 90us/step - loss: 0.3654 - acc: 0.8127\n",
      "Epoch 362/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3623 - acc: 0.8121\n",
      "Epoch 363/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3680 - acc: 0.8104\n",
      "Epoch 364/2000\n",
      "7745/7745 [==============================] - 1s 94us/step - loss: 0.3633 - acc: 0.8122\n",
      "Epoch 365/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3630 - acc: 0.8138\n",
      "Epoch 366/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3630 - acc: 0.8140\n",
      "Epoch 367/2000\n",
      "7745/7745 [==============================] - 1s 88us/step - loss: 0.3655 - acc: 0.8125\n",
      "Epoch 368/2000\n",
      "7745/7745 [==============================] - 1s 85us/step - loss: 0.3641 - acc: 0.8140\n",
      "Epoch 369/2000\n",
      "7745/7745 [==============================] - 1s 87us/step - loss: 0.3649 - acc: 0.8157\n",
      "Epoch 370/2000\n",
      "7745/7745 [==============================] - 1s 91us/step - loss: 0.3670 - acc: 0.8102\n",
      "Epoch 371/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3621 - acc: 0.8131\n",
      "Epoch 372/2000\n",
      "7745/7745 [==============================] - 1s 91us/step - loss: 0.3617 - acc: 0.8120\n",
      "Epoch 373/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3639 - acc: 0.8124\n",
      "Epoch 374/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3653 - acc: 0.8146\n",
      "Epoch 375/2000\n",
      "7745/7745 [==============================] - 1s 90us/step - loss: 0.3685 - acc: 0.8133\n",
      "Epoch 376/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3655 - acc: 0.8130\n",
      "Epoch 377/2000\n",
      "7745/7745 [==============================] - 1s 85us/step - loss: 0.3637 - acc: 0.8116\n",
      "Epoch 378/2000\n",
      "7745/7745 [==============================] - 1s 91us/step - loss: 0.3623 - acc: 0.8161\n",
      "Epoch 379/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3658 - acc: 0.8122\n",
      "Epoch 380/2000\n",
      "7745/7745 [==============================] - 1s 88us/step - loss: 0.3641 - acc: 0.8136\n",
      "Epoch 381/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3647 - acc: 0.8110\n",
      "Epoch 382/2000\n",
      "7745/7745 [==============================] - 1s 84us/step - loss: 0.3641 - acc: 0.8140\n",
      "Epoch 383/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3664 - acc: 0.8106\n",
      "Epoch 384/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3634 - acc: 0.8138\n",
      "Epoch 385/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3620 - acc: 0.8173\n",
      "Epoch 386/2000\n",
      "7745/7745 [==============================] - 1s 87us/step - loss: 0.3664 - acc: 0.8104\n",
      "Epoch 387/2000\n",
      "7745/7745 [==============================] - 1s 83us/step - loss: 0.3653 - acc: 0.8120\n",
      "Epoch 388/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3674 - acc: 0.8125\n",
      "Epoch 389/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3677 - acc: 0.8118\n",
      "Epoch 390/2000\n",
      "7745/7745 [==============================] - 1s 92us/step - loss: 0.3619 - acc: 0.8146\n",
      "Epoch 391/2000\n",
      "7745/7745 [==============================] - 1s 90us/step - loss: 0.3619 - acc: 0.8133\n",
      "Epoch 392/2000\n",
      "7745/7745 [==============================] - 1s 90us/step - loss: 0.3652 - acc: 0.8151\n",
      "Epoch 393/2000\n",
      "7745/7745 [==============================] - 1s 88us/step - loss: 0.3611 - acc: 0.8139\n",
      "Epoch 394/2000\n",
      "7745/7745 [==============================] - 1s 90us/step - loss: 0.3644 - acc: 0.8151\n",
      "Epoch 395/2000\n",
      "7745/7745 [==============================] - 1s 89us/step - loss: 0.3653 - acc: 0.8111\n",
      "Epoch 396/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3582 - acc: 0.8164\n",
      "Epoch 397/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3655 - acc: 0.8116\n",
      "Epoch 398/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3632 - acc: 0.8146\n",
      "Epoch 399/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3652 - acc: 0.8108\n",
      "Epoch 400/2000\n",
      "7745/7745 [==============================] - 1s 84us/step - loss: 0.3638 - acc: 0.8141\n",
      "Epoch 401/2000\n",
      "7745/7745 [==============================] - 1s 91us/step - loss: 0.3617 - acc: 0.8154\n",
      "Epoch 402/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7745/7745 [==============================] - 1s 90us/step - loss: 0.3607 - acc: 0.8139\n",
      "Epoch 403/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3645 - acc: 0.8133\n",
      "Epoch 404/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3657 - acc: 0.8118\n",
      "Epoch 405/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3615 - acc: 0.8138\n",
      "Epoch 406/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3645 - acc: 0.8111\n",
      "Epoch 407/2000\n",
      "7745/7745 [==============================] - 1s 76us/step - loss: 0.3664 - acc: 0.8139\n",
      "Epoch 408/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3645 - acc: 0.8120\n",
      "Epoch 409/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3612 - acc: 0.8122\n",
      "Epoch 410/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3605 - acc: 0.8141\n",
      "Epoch 411/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3638 - acc: 0.8124\n",
      "Epoch 412/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3650 - acc: 0.8113\n",
      "Epoch 413/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3598 - acc: 0.8150\n",
      "Epoch 414/2000\n",
      "7745/7745 [==============================] - 1s 82us/step - loss: 0.3633 - acc: 0.8091\n",
      "Epoch 415/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3643 - acc: 0.8121\n",
      "Epoch 416/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3628 - acc: 0.8117\n",
      "Epoch 417/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3637 - acc: 0.8121\n",
      "Epoch 418/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3634 - acc: 0.8109\n",
      "Epoch 419/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3591 - acc: 0.8179\n",
      "Epoch 420/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3655 - acc: 0.8131\n",
      "Epoch 421/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3631 - acc: 0.8144\n",
      "Epoch 422/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3616 - acc: 0.8137\n",
      "Epoch 423/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3620 - acc: 0.8145\n",
      "Epoch 424/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3611 - acc: 0.8137\n",
      "Epoch 425/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3632 - acc: 0.8130\n",
      "Epoch 426/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3650 - acc: 0.8107\n",
      "Epoch 427/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3638 - acc: 0.8127\n",
      "Epoch 428/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3642 - acc: 0.8113\n",
      "Epoch 429/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3638 - acc: 0.8124\n",
      "Epoch 430/2000\n",
      "7745/7745 [==============================] - 1s 77us/step - loss: 0.3644 - acc: 0.8130\n",
      "Epoch 431/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3589 - acc: 0.8159\n",
      "Epoch 432/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3632 - acc: 0.8140\n",
      "Epoch 433/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3650 - acc: 0.8099\n",
      "Epoch 434/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3628 - acc: 0.8127\n",
      "Epoch 435/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3631 - acc: 0.8117\n",
      "Epoch 436/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3632 - acc: 0.8121\n",
      "Epoch 437/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3655 - acc: 0.8107\n",
      "Epoch 438/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3645 - acc: 0.8118\n",
      "Epoch 439/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3623 - acc: 0.8125\n",
      "Epoch 440/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3609 - acc: 0.8135\n",
      "Epoch 441/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3628 - acc: 0.8136\n",
      "Epoch 442/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3622 - acc: 0.8155\n",
      "Epoch 443/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3620 - acc: 0.8132\n",
      "Epoch 444/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3622 - acc: 0.8140\n",
      "Epoch 445/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3628 - acc: 0.8131\n",
      "Epoch 446/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3611 - acc: 0.8133\n",
      "Epoch 447/2000\n",
      "7745/7745 [==============================] - 1s 80us/step - loss: 0.3626 - acc: 0.8115\n",
      "Epoch 448/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3619 - acc: 0.8147\n",
      "Epoch 449/2000\n",
      "7745/7745 [==============================] - 1s 78us/step - loss: 0.3637 - acc: 0.8127\n",
      "Epoch 450/2000\n",
      "7745/7745 [==============================] - 1s 79us/step - loss: 0.3632 - acc: 0.8149\n",
      "Epoch 451/2000\n",
      "7745/7745 [==============================] - 1s 81us/step - loss: 0.3643 - acc: 0.8121\n",
      "Epoch 452/2000\n",
      "4000/7745 [==============>...............] - ETA: 0s - loss: 0.3597 - acc: 0.8152"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2000, batch_size=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3815/3815 [==============================] - 0s 98us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3586324231965201, 0.6465705583636132]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliar precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.0 %\n"
     ]
    }
   ],
   "source": [
    "dfx = df_[int(-df_.shape[0]/20):]\n",
    "prec = []\n",
    "for idx, dfr in dfx.iterrows():\n",
    "    \n",
    "    prep = [prepare(dfr['Home'],dfr['Away'])]\n",
    "    \n",
    "    prepx = np.array(prep).reshape(np.array(prep).shape[0],np.array(prep).shape[2]*2)\n",
    "    \n",
    "    p = model.predict(prepx)\n",
    "    \n",
    "    if p[0,0] > p[0,1] and p[0,0] > p[0,2]:\n",
    "        px = 'H'\n",
    "        \n",
    "    if p[0,2] > p[0,1] and p[0,2] > p[0,0]:\n",
    "        px = 'A'\n",
    "        \n",
    "    if p[0,1] > p[0,0] and p[0,1] > p[0,2]:\n",
    "        px = 'D'\n",
    "    \n",
    "    prec.append(1 if px == dfr['Res'] else 0)\n",
    "    \n",
    "    dfx.loc[idx]['S'] = 'G' if px == dfr['Res'] else 'P'\n",
    "\n",
    "print(round((abs(np.mean(prec))) * 100,0), '%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Concurso                   S\n",
       "Concurso 785 (05/02/2018)  G     2\n",
       "Concurso 786 (14/02/2018)  G    11\n",
       "Concurso 787 (20/02/2018)  G     7\n",
       "Concurso 788 (26/02/2018)  G    11\n",
       "Concurso 789 (05/03/2018)  G     9\n",
       "Concurso 790 (12/03/2018)  G     7\n",
       "Concurso 791 (19/03/2018)  G     7\n",
       "Concurso 792 (26/03/2018)  G    13\n",
       "Concurso 793 (02/04/2018)  G    12\n",
       "Concurso 794 (09/04/2018)  G    11\n",
       "Concurso 795 (16/04/2018)  G    10\n",
       "Concurso 796 (23/04/2018)  G     9\n",
       "Concurso 797 (30/04/2018)  G     7\n",
       "Concurso 798 (07/05/2018)  G     7\n",
       "Concurso 799 (14/05/2018)  G     7\n",
       "Concurso 800 (21/05/2018)  G    11\n",
       "Concurso 801 (28/05/2018)  G     8\n",
       "Concurso 802 (04/06/2018)  G     7\n",
       "Concurso 803 (11/06/2018)  G     6\n",
       "Concurso 804 (18/06/2018)  G    13\n",
       "Concurso 805 (25/06/2018)  G    11\n",
       "Concurso 806 (28/06/2018)  G    10\n",
       "Concurso 807 (02/07/2018)  G     9\n",
       "Concurso 808 (09/07/2018)  G    13\n",
       "Concurso 809 (16/07/2018)  G     9\n",
       "Concurso 810 (23/07/2018)  G    10\n",
       "Concurso 811 (30/07/2018)  G     9\n",
       "Concurso 812 (06/08/2018)  G     8\n",
       "Concurso 813 (13/08/2018)  G     9\n",
       "Concurso 814 (20/08/2018)  G     8\n",
       "Concurso 815 (27/08/2018)  G    10\n",
       "Concurso 816 (03/09/2018)  G     7\n",
       "Concurso 817 (10/09/2018)  G     9\n",
       "Concurso 818 (17/09/2018)  G     8\n",
       "Concurso 819 (25/09/2018)  G     8\n",
       "Concurso 820 (01/10/2018)  G     8\n",
       "Concurso 821 (08/10/2018)  G     7\n",
       "Concurso 822 (15/10/2018)  G    11\n",
       "Concurso 823 (22/10/2018)  G    10\n",
       "Concurso 824 (29/10/2018)  G     8\n",
       "Concurso 825 (05/11/2018)  G     6\n",
       "Concurso 826 (12/11/2018)  G     7\n",
       "Name: S, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx[dfx['S']=='G'].groupby(['Concurso'])['S'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(dfx['S'].value_counts().keys(),dfx['S'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 'ATLÉTICO/MG'\n",
    "A = 'SANTOS/SP'\n",
    "\n",
    "prep = [prepare(H,A)]\n",
    "    \n",
    "prepx = np.array(prep).reshape(np.array(prep).shape[0],np.array(prep).shape[1]*2)\n",
    "    \n",
    "p = model.predict(prepx)\n",
    "\n",
    "\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
